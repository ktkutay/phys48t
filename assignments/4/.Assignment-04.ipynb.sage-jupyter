{"kernelspec":{"display_name":"Python 2 (SageMath)","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.10"}}
{"cell_type":"markdown","metadata":{},"source":"# Assignment 4: Manipulating data part 2, and \"human learning\""}
{"cell_type":"markdown","metadata":{},"source":"In this assigmnent, we will continue our dive into the tasks of manipulating and cleaning data, and will try to learn from a dataset as humans.\n\n- I will stop using the __`[ HW ]`__ notation from now on. Please read and follow all the instructions in the notebook."}
{"cell_type":"markdown","metadata":{},"source":"## Reading, inspecting, cleaning data to prepare for learning"}
{"cell_type":"code","execution_count":102,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"application/javascript":"\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"}],"source":"# As we did in the previous assignment, import the libraries Pandas,\n# NumPy, Matplotlib, Seaborn, and run the appropriate IPython magic\n# command for Matplotlib to make the plots display inside the notebook \n# (inline). \n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \n\n##disable ipython autoscroll for large outputs\nfrom IPython.display import display, Javascript\ndisable_js = \"\"\"\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n\"\"\"\ndisplay(Javascript(disable_js))"}
{"cell_type":"markdown","metadata":{},"source":"As in the previous assignment, you will find the two datasets, `income_train.csv` and `income_test.csv` in the `data` subdirectory. \n\nUse Pandas to read the two data files into DataFrame objects named `income_train` and `income_test`. \nRecall that the symbol `?` stands for a missing value; make sure to take that into account when\nreading the data. Once you read the two datasets, display their \"head\"s (i.e., their first few rows). "}
{"cell_type":"code","execution_count":103,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::b4661e9a-ba63-4e52-8025-8dce14ae717f","text/plain":"smc-blob::f8838cd7-9655-44d0-bf57-7a5f52824c48"},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":"income_train = pd.read_csv('data/income_train.csv', na_values=['?'])\nincome_test = pd.read_csv('data/income_test.csv', na_values=['?'])\n\nincome_train.head()"}
{"cell_type":"code","execution_count":104,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::0c1dec71-cd21-4ddc-b748-bc26e43df957","text/plain":"smc-blob::bc7fb782-c9f1-4c88-ac25-2f2b64694d19"},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":"income_test.head()"}
{"cell_type":"markdown","metadata":{},"source":"Do you notice something interesting/weird when you look at/compare the two datasets? Don't worry if not, we will explore the weirdness below, but it is always a good idea to take a look at the raw data with your naked eyes, even if just a few rows of it. If you can remind me during our next meeting, I'll tell you a relevant personal [war story](http://www.merriam-webster.com/dictionary/war%20story) involving months of confusion and a lot of money (not mine!)"}
{"cell_type":"markdown","metadata":{},"source":"In the last homework, we obtained the lists of unique values that occur in all the categorical columns of the data set `income_train`. Let's do the same thing for both of the datasets now.\n\n- As in the last homework, define two lists, `cat_cols_train` and `cat_cols_test` that contains the list of categorical columns in the two datasets. \n- Confirm that the two lists consist of the same elements."}
{"cell_type":"code","execution_count":105,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"## your code here\n\ncat_cols_train = [c for c in income_train.columns if income_train[c].dtype is np.dtype(object)]\ncat_cols_test =  [c for c in income_test.columns if income_test[c].dtype is np.dtype(object)]"}
{"cell_type":"markdown","metadata":{},"source":"Next, create two dictionaries, `train_categories` and `test_categories`, where the __keys__ of the dictionary are the categorical column names, and the __values__ in the dictionary contain the unique values that occur in the corresponding category. (Read on Python dictionaries if you need to refresh your memory on keys and values)\n\nFor example, since we have"}
{"cell_type":"code","execution_count":106,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"['Male' 'Female']\n"}],"source":"print income_train['sex'].unique()"}
{"cell_type":"markdown","metadata":{},"source":"the `'sex'` key in the `train_categories` dictionary will have the value `['Male', 'Female']`."}
{"cell_type":"code","execution_count":107,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"# Create dictionaries containing the unique categories for all the categorical \n# columns (one dictionary per dataset). You are free to do this in any way you want, but\n# the \"dictionary comprehension\" technique we saw in the last homework is a quite practical\n# (and idiomatic) way.\n\n## your code here \n\ntrain_categories = {c:income_train[c].unique() for c in cat_cols_train}\ntest_categories = {c:income_test[c].unique() for c in cat_cols_test}"}
{"cell_type":"markdown","metadata":{},"source":"Next, let's check if the two sets of categories agree. Create a list, `disagree_cols`, that holds the names of the columns for which the lists of categories don't agree between the two datasets. Please do this programmatically, i.e., don't create these lists by manually selecting the columns after visually inspecting them (you are free to visually inspect them if you want, though). \n\nThis should give you two columns."}
{"cell_type":"markdown","metadata":{},"source":"Again, you are free to do this any way you want, but here is a helpful trick if you want to use it:"}
{"cell_type":"code","execution_count":108,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"As sets rather than lists:\na==b:  True\na==c:  True\na==d:  False\na!=d:  True\n"}],"source":"# Helpful trick: Sets as unordered lists in Python \n# Execute/modify to see/inspect behavior\n\na=['x','y','z']\nb=['y','z','x'] # changed order\nc=['x','y','y','z'] # repeated elements\nd=['x','y','z','t'] # new element\n\nprint \"As sets rather than lists:\"\nprint \"a==b: \", set(a) == set(b)\nprint \"a==c: \", set(a) == set(c)\nprint \"a==d: \", set(a) == set(d)\nprint \"a!=d: \", set(a) != set(d)"}
{"cell_type":"markdown","metadata":{},"source":"Now let's get the `disagree_cols`."}
{"cell_type":"code","execution_count":109,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"['yearly-income', 'native-country']\n"}],"source":"# Obtain the list of categorical columns where the unique cats don't agree \n# between the two datasets (you should find two!)\n\n## Your code here\n\ndisagree_cols = [key for key in train_categories if set(train_categories[key]) != set(test_categories[key])]\nprint disagree_cols\n\n#for key,value in train_categories.iteritems():\n#    print key,set(train_categories[key]) == set(test_categories[key])"}
{"cell_type":"markdown","metadata":{},"source":"Next, print the unique values that occur in the two datasets for the two \"disagree columns\", together with the corresponding unique values in the two datasets. "}
{"cell_type":"code","execution_count":110,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Column:  yearly-income\ntrain: \n['<=50K' '>50K']\ntest: \n['<=50K.' '>50K.']\nColumn:  native-country\ntrain: \n['United-States' 'Cuba' 'Jamaica' 'India' nan 'Mexico' 'South'\n 'Puerto-Rico' 'Honduras' 'England' 'Canada' 'Germany' 'Iran' 'Philippines'\n 'Italy' 'Poland' 'Columbia' 'Cambodia' 'Thailand' 'Ecuador' 'Laos'\n 'Taiwan' 'Haiti' 'Portugal' 'Dominican-Republic' 'El-Salvador' 'France'\n 'Guatemala' 'China' 'Japan' 'Yugoslavia' 'Peru'\n 'Outlying-US(Guam-USVI-etc)' 'Scotland' 'Trinadad&Tobago' 'Greece'\n 'Nicaragua' 'Vietnam' 'Hong' 'Ireland' 'Hungary' 'Holand-Netherlands']\ntest: \n['United-States' nan 'Peru' 'Guatemala' 'Mexico' 'Dominican-Republic'\n 'Ireland' 'Germany' 'Philippines' 'Thailand' 'Haiti' 'El-Salvador'\n 'Puerto-Rico' 'Vietnam' 'South' 'Columbia' 'Japan' 'India' 'Cambodia'\n 'Poland' 'Laos' 'England' 'Cuba' 'Taiwan' 'Italy' 'Canada' 'Portugal'\n 'China' 'Nicaragua' 'Honduras' 'Iran' 'Scotland' 'Jamaica' 'Ecuador'\n 'Yugoslavia' 'Hungary' 'Hong' 'Greece' 'Trinadad&Tobago'\n 'Outlying-US(Guam-USVI-etc)' 'France']\n"}],"source":"# Let me do this for you: Execute this cell after you have the needed variables below defined\n\nfor c in disagree_cols:\n    print \"Column: \", c\n    print \"train: \"\n    print train_categories[c]\n    print \"test: \"\n    print test_categories[c]"}
{"cell_type":"markdown","metadata":{},"source":"Different categories can sometimes naturally occur in two different datasets from the same source, but different sets of categories can signify an error, too. Looking at the outcome of the print statement above, you should see that the reason for the discrepancy in one of the columns is a clear error. Let's next fix that error.\n\nYou should have found that for one of the \"disagree columns\", the categories in `income_test` are almos equal to those in `income_train`, with one additional character added at the end for each category.\n\nCreate a copy of `income_test` named `income_test_corrected`, and update the relevant column in this DataFrame to make the unique categories agree with those in `income_train`; in other words, remove the extra character in the relevant column of `income_test_corrected`.\n\nNote that there are various ways to do this in Pandas; you can use, e.g., the `map()` or the `apply()` methods."}
{"cell_type":"code","execution_count":111,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"# Let me create the copy for you \nincome_test_corrected = income_test.copy()\n# Now correct the troublesome column\nincome_test_corrected[\"yearly-income\"] = income_test[\"yearly-income\"].map({\"<=50K.\": \"<=50K\", \">50K.\": \">50K\"})\n#income_test_corrected.head()"}
{"cell_type":"markdown","metadata":{},"source":"After correcting the trouble column in `income_test_corrected`, save this corrected version to the `data` directory using the `to_csv()` method in Pandas, but use a new file name, e.g., `income_test_corrected.csv` to avoid overwriting the existing file. Note that \n\n- we don't want to write index of the DataFrame object, so use an appropriate setting for the `index` parameter of `to_csv()`\n- we would like to use the `?` symbol for the missing values (instead of the default symbol Pandas uses), so use the appropriate parameter and an appropriate setting for that parameter of `to_csv()`"}
{"cell_type":"code","execution_count":112,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"income_test_corrected.to_csv(\"data/income_test_corrected.csv\",index=False,na_rep=\"?\")"}
{"cell_type":"markdown","metadata":{},"source":"## \"Human learning\""}
{"cell_type":"markdown","metadata":{},"source":"We will soon start to learn techniques of machine learning; i.e., letting a computer program go over the data to learn to predict an outcome of interest using the data available. For the `income` datasets, we would like to learn how to  predict the `yearly-income` column using the information in the other columns. \n\nIn this second part of the homework, I want you to use visualization and exploratory data-analysis to create a hand-made prediction function; i.e., instead of machine learning, learn from the data as a human, and write a prediction rule function. The function should take a DataFrame object with the same columns as in the two datasets income_train and income_test (except possibly the `yearly-income` column), __and returns a NumPy array (or Pandas Series object) of predictions of the `yearly-income` column__, with one prediction per row.\n\nOnce you have your predictive function, evaluate it on the test set (`income_test`) by making predictions of it `yearly-income` column, and obtaining the fraction of correct answers. \n\nHere are the rules:\n\n- Show me your exploratory work. It is ok (in fact, more than ok!) to show things you tried and didn't work.\n- You must not use `income_test` for your exploratory, development, and preliminary evaluation work. You can only use it once you are satisfied with your prediction function and how it performs on `income_train`, and are ready to get the final evaluation on the test set. This is the purpose of having a separate test set!\n\nThis part of the assignment is open-ended, but it will be evaluated on a \"reasonable effort\" basis. I don't expect you to get a highly accurate function, my aim here is to let you have this experience of trying to learn from data,  and perhaps brainstorm a bit about how a machine (algorithm) may do this automatically. I am __not__ asking you to use machine learning; please don't! Just try to learn from this dataset as a human, and write a hard-coded prediction function. Use this as an opportunity to try out different visualization and data summarization techniques. And have fun!\n\nJust to make things concrete, I'm including one simple attempt below. Please note that this code assumes the corrected test data `income_test_corrected` has been created already.\n\nThis section will be worth 5 points."}
{"cell_type":"markdown","metadata":{},"source":"### Example solution from Arkadaş"}
{"cell_type":"markdown","metadata":{},"source":"Get the fractions of the two categories."}
{"cell_type":"code","execution_count":113,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<=50K    0.75919\n>50K     0.24081\nName: yearly-income, dtype: float64"},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":"income_train['yearly-income'].value_counts(normalize=True)"}
{"cell_type":"markdown","metadata":{},"source":"About 75.9% have income <=50K, so if we predict everybody has income <=50K, we will have 75.9% correct answers on income_train. Let's see if we can do better."}
{"cell_type":"markdown","metadata":{},"source":"Inspect dependence of the yearly-income on the workclass."}
{"cell_type":"code","execution_count":114,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"import seaborn as sns"}
{"cell_type":"code","execution_count":115,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"<seaborn.axisgrid.FacetGrid at 0x7fba2e5a03d0>"},"execution_count":115,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::0bd847fe-0d1a-4e01-9b68-7e3377648be7","text/plain":"<matplotlib.figure.Figure at 0x7fba2e4bb910>"},"metadata":{},"output_type":"display_data"}],"source":"sns.factorplot(\"yearly-income\", col=\"workclass\", col_wrap=4, data=income_train, kind=\"count\")"}
{"cell_type":"markdown","metadata":{},"source":"Looks like for workclass=Self-emp-inc, there are more people with >50K than <=50K. Let's check."}
{"cell_type":"code","execution_count":116,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":">50K     0.557348\n<=50K    0.442652\nName: yearly-income, dtype: float64\n"}],"source":"# Restrict to subset (read about Boolean (logical) indexing from the Pandas docs if this looks mysterious)\nincome_train_self_emp = income_train[ income_train['workclass']=='Self-emp-inc' ]\n\n# Print normalized value counts\nprint income_train_self_emp['yearly-income'].value_counts(normalize=True)"}
{"cell_type":"markdown","metadata":{},"source":"Looks like our observation was correct. So if somebody's workclass is 'Self-emp-inc', we can predict they have income >50K, and we will do better. Let's use this observation to create our prediction function."}
{"cell_type":"code","execution_count":117,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"# Function that takes in a data frame ('df') and returns the predicted yearly-income for each row\ndef predict_income(df):\n    # Default prediction: everybody is <=50K\n    # Repeat this default prediction as many times as there are rows in the input dataset df\n    predictions = np.repeat(['<=50K'], len(df))\n\n    # Find the rows where workclass is 'Self-emp-inc'; this creates a Boolean (logical) NumPy array\n    self_emp_rows = np.array(df['workclass'] == 'Self-emp-inc')\n\n    # Update the predictions for the corresponding rows\n    # We will use logical (boolean) indexing for a NumPy array\n    predictions[self_emp_rows] = '>50K'\n    return predictions"}
{"cell_type":"markdown","metadata":{},"source":"Let's now predict for the training set."}
{"cell_type":"code","execution_count":118,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"train_predictions = predict_income(income_train)"}
{"cell_type":"markdown","metadata":{},"source":"How well did we do?"}
{"cell_type":"code","execution_count":119,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"train_correct_predictions = np.array(train_predictions == income_train['yearly-income'])"}
{"cell_type":"markdown","metadata":{},"source":"`train_correct_predictions` is a Boolean array. True is treated as 1 and False is treated as 0, so calculating the mean gives the fraction of correct answers."}
{"cell_type":"code","execution_count":120,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"0.76312152575166614"},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":"train_correct_predictions.mean()"}
{"cell_type":"markdown","metadata":{},"source":"We improved on the baseline of 0.759...!"}
{"cell_type":"markdown","metadata":{},"source":"So now that we are happy with our prediction rule, let's evaluate it on the test set. But beware, there is no going back to create another prediction rule after looking at the test set; if we are unhappy about our prediction function now, we should work to improve before doing the final check on the test set. I'm happy with the 76.3% so I'm going for the final evaluation."}
{"cell_type":"code","execution_count":121,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"test_predictions = predict_income(income_test_corrected)"}
{"cell_type":"code","execution_count":122,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"test_correct_predictions = np.array(test_predictions == income_test_corrected['yearly-income'])"}
{"cell_type":"code","execution_count":123,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"0.76702905226951656"},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":"test_correct_predictions.mean()"}
{"cell_type":"markdown","metadata":{},"source":"## Your solution "}
{"cell_type":"code","execution_count":124,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"mean_by = income_train.groupby(\"yearly-income\").mean()"}
{"cell_type":"code","execution_count":125,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::4b6050a0-ab64-4b9d-9853-e5489940bc04","text/plain":"                     age        fnlwgt  education-num  capital-gain  \\\nyearly-income                                                         \n<=50K          36.783738  190340.86517       9.595065    148.752468   \n>50K           44.249841  188005.00000      11.611657   4006.142456   \n\n               capital-loss  hours-per-week  \nyearly-income                                \n<=50K             53.142921       38.840210  \n>50K             195.001530       45.473026  "},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":"mean_by.head()"}
{"cell_type":"code","execution_count":126,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"std_by = income_train.groupby(\"yearly-income\").std()"}
{"cell_type":"code","execution_count":127,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/html":"smc-blob::e344c765-3ed0-4ff7-98c7-67deae6b1f4f","text/plain":"                     age         fnlwgt  education-num  capital-gain  \\\nyearly-income                                                          \n<=50K          14.020088  106482.271195       2.436147    963.139307   \n>50K           10.519028  102541.775472       2.385129  14570.378951   \n\n               capital-loss  hours-per-week  \nyearly-income                                \n<=50K            310.755769       12.318995  \n>50K             595.487574       11.012971  "},"execution_count":127,"metadata":{},"output_type":"execute_result"}],"source":"std_by.head()"}
{"cell_type":"markdown","metadata":{},"source":"__it seems like increased education-num, capital-gain and hours-per-week increases yearly-income__, capital gain and capital loss are not good measures as they have high std"}
{"cell_type":"code","execution_count":128,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"def my_predict_income(df):\n    predictions = np.repeat(['<=50K'], len(df))\n\n    high_income = np.array(df['age'] > 40)# and df['education-num'] > 10.6 and df['hours-per-week'] > 42.1)\n\n    predictions[high_income] = '>50K'\n    return predictions"}
{"cell_type":"code","execution_count":129,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"my_train_predictions = my_predict_income(income_train)"}
{"cell_type":"code","execution_count":130,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"0.63827892263751118"},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":"my_train_correct_predictions = np.array(my_train_predictions == income_train['yearly-income'])\nmy_train_correct_predictions.mean()\n#meeeh not good"}
{"cell_type":"code","execution_count":131,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"def my_predict_income(df):\n    predictions = np.repeat(['<=50K'], len(df))\n\n    high_income = np.array(df['hours-per-week'] > 40)\n\n    predictions[high_income] = '>50K'\n    return predictions"}
{"cell_type":"code","execution_count":156,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/projects/sage/sage-7.3/local/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"},{"data":{"text/plain":"0.75912901937901167"},"execution_count":156,"metadata":{},"output_type":"execute_result"}],"source":"my_train_predictions = my_predict_income(income_train)\nmy_train_correct_predictions = np.array(my_train_predictions == income_train['yearly-income'])\nmy_train_correct_predictions.mean()\n# still not ok :( "}
{"cell_type":"code","execution_count":133,"metadata":{"collapsed":false,"scrolled":true,"trusted":true},"outputs":[],"source":"# plt.plot(income_train['yearly-income'].map({\"<=50K\":20, \">50K\": 70}),income_train['hours-per-week'] , '.')\n# tried to visualize hours per week by yearly-income to see whether if it is regressable."}
{"cell_type":"code","execution_count":134,"metadata":{"collapsed":false,"trusted":true},"outputs":[],"source":"#income_dummy_vals = income_train['yearly-income']\n#income_train[\"yearly-income-bool\"] = [51*income_train[\"age\"][key] if income == \">50K\" else 49*income_train[\"age\"][key] for key,income in income_train[\"yearly-income\"].iteritems()]\n\nincome_train[\"yearly-income-bool\"] = [True if income == \">50K\" else False for key,income in income_train[\"yearly-income\"].iteritems()]"}
{"cell_type":"code","execution_count":135,"metadata":{"collapsed":false,"scrolled":true,"trusted":true},"outputs":[{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7fba2e05b490>]"},"execution_count":135,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::43fd8416-0d06-4206-990f-5b09ded363da","text/plain":"<matplotlib.figure.Figure at 0x7fba2e4bb310>"},"metadata":{},"output_type":"display_data"}],"source":"p_by_age = income_train[[\"age\", \"yearly-income-bool\"]].groupby(\"age\").mean() #probabilities of earning higher than >50K by age.\nplt.plot(income_train[[\"age\", \"yearly-income-bool\"]].groupby(\"age\").mean())"}
{"cell_type":"code","execution_count":136,"metadata":{"collapsed":false,"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"yearly-income-bool    0.223022\ndtype: float64 yearly-income-bool    0.138112\ndtype: float64\n"}],"source":"p_mean = p_by_age.mean()\np_std = p_by_age.std()\nprint p_mean,p_std"}
{"cell_type":"code","execution_count":154,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/projects/sage/sage-7.3/local/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"},{"data":{"text/plain":"0.75912901937901167"},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":"def my_predict_income(df):\n    predictions = np.repeat(['<=50K'], len(df))\n    \n    df[\"yearly-income-bool\"] = income_train[\"yearly-income\"].map({\"<=50K\": False, \">50K\": True})\n    p_by_age = df[[\"age\", \"yearly-income-bool\"]].groupby(\"age\").mean()\n    p_by_age_mean = p_by_age['yearly-income-bool'].mean()\n    high_income = [True if p_by_age[\"yearly-income-bool\"][age] > p_by_age_mean else False for age in df[\"age\"]]\n    predictions[high_income] = '>50K'\n    return predictions\n\nmy_train_predictions = my_predict_income(income_train)\nmy_train_correct_predictions = np.array(my_train_predictions == income_train['yearly-income'])\nmy_train_correct_predictions.mean()"}
{"cell_type":"markdown","metadata":{},"source":"__IT SEEMS REALLY NICE!__ Now try in test :)"}
{"cell_type":"code","execution_count":155,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/projects/sage/sage-7.3/local/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"},{"data":{"text/plain":"0.76365088139549164"},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":"my_test_predictions = my_predict_income(income_test_corrected)\nmy_test_correct_predictions = np.array(my_test_predictions == income_test_corrected['yearly-income'])\nmy_test_correct_predictions.mean()"}
{"cell_type":"markdown","metadata":{},"source":"# 0.764\n## WOW! :)"}