{"kernelspec":{"display_name":"Python 2 (SageMath)","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.10"}}
{"cell_type":"markdown","metadata":{},"source":"# Assignment 04: Who who survived the Titanic?\n\nIn this assignment, we will get some practical experience with classification trees, and tune our first machine learning model. As mentioned in a couple of course emails, we will be using the \"decision tree classifier\" implementation in the Python package [scikit-learn](http://scikit-learn.org/stable/documentation.html). Go check out the documentation/tutorial pages of this package, it is a great resource. We will use only classification trees in this homework, but the workflow is very similar in many different, and more advanced types of machine learning methods. The great utility of a package like scikit-learn means you can very easily start tuning and using sophisticated machine learning models to make predictions, even if you are not familiar with the underlying algorithms. But there is one important thing to keep in mind: **The danger zone!**\n\n<img width=\"300\" src=\"./img/danger_zone.png\"></img>\n\nIf you have a prediction/detection problem to solve in your research field and you have access to the advanced tools of machine learning, it is very tempting to just leave learning about the various statistical subtleties to a later time, and just jump into the (admittedly, fun) task of building models. This is a dangerous thing to do, because there are a bunch of pitfalls in this field that make it very easy to fool yourself into thinking you have good models, when in fact you don't. One of the most important questions along these lines is how to tune and evaluate a model properly. In this homework we will try to lay the groundwork for this. \n\nAs mentioned in the pre-homework email, we will be using the _Titanic_ dataset from Kaggle. In contrast to the previous homeworks, I have not uploaded the data into the assignment directory for SMC; part of the aim of this homework is to get you familiarized with the workings of Kaggle, so your first task will be to download the datasets to your computers, and then upload them to the directory of this assignment on SMC. \n\nBut first, we will start with a small lecture/tutorial on classification trees and how to tune them. \n\n<!---\n[//]: # - Notes about\n[//]: # - Split criterion; quantifying the quality of a split\n[//]: # - How to select the next node to split: Depth-first vs. breadth-first, greediness\n[//]: # - Kaggle & Titanic: https://www.kaggle.com/c/titanic\n\n\n[//]: # http://scikit-learn.org/stable/modules/tree.html\n[//]: # http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n\n[//]: # https://www.kaggle.com/c/titanic/details/getting-started-with-python\n[//]: # https://www.kaggle.com/c/titanic/details/getting-started-with-python-ii\n[//]: # https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests\n[//]: # \n[//]: # https://www.kaggle.com/c/titanic/data\n--->"}
{"cell_type":"markdown","metadata":{},"source":"# Introduction to classification trees: A tutorial"}
{"cell_type":"markdown","metadata":{},"source":"I am preparing this section of the notebook as a tutorial, I encourage you to try out the commands and play around  with it to familiarize yourself with the concepts. If you see that I use a function that you are not familiar with, feel free to try it out yourself to see what it does."}
{"cell_type":"markdown","metadata":{},"source":"### Create a synthetic dataset"}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_palette(sns.color_palette('Paired'))\n\n%matplotlib inline"}
{"cell_type":"markdown","metadata":{},"source":"Start by defining a few functions to create a synthetic dataset. We will use machine learning to learn from from this dataset.\n\nThe datasets will be created by sampling points inside a square using a uniform distribution, and labeling them according to their distance from the origin; points closer than a distance of 1 will be called 'near', and others will be called 'far'. To make the setting a bit closer to \"real life\", we will add some noise to the data by switching the labels of some of the points randomly."}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"# Try out np.repeat and np.tile to see what they do\n\ndef create_data(n_points, p_flip=0.1):\n    \"\"\"Returns a dataframe with columns X1, X2, y. First creates an \n    (n_grid x n_grid) square inside 0 < X1, X2 < 2, and then labels the \n    points on this grid as 'near' if they are a distance of < 1 from the \n    origin, 'far' otherwise. Finally, randomly flips the labels with a\n    probability of p_flip. The labels are contained in column y.\"\"\"\n\n    # Sample from the interval [0,2] using the uniform distribution\n    X1 = np.random.rand(n_points) * 2\n    X2 = np.random.rand(n_points) * 2\n    X = np.column_stack([X1,X2])\n\n    # The output variable measures whether the distance is < 1\n    y = np.sum(X*X,axis=1) < 1\n\n    # The y entries to flip, randomly sampled\n    flip = np.random.choice([True, False], size=len(y), p=[p_flip, 1-p_flip])\n    y = np.logical_xor(y, flip)\n\n    # Change the labeling from True/False to \"near\", \"far\"\n    y = np.where(y, 'near', 'far')\n\n    # Return data frame\n    return pd.DataFrame({'X1': X1, 'X2': X2, 'y':y})"}
{"cell_type":"markdown","metadata":{},"source":"Next, we create a simple plotting functions to visualize the dataset. We are using a very useful Pandas method called `groupby()`, which I mentioned in a previous assignment. If you are not familiar with it, you can read about it [here](http://pandas.pydata.org/pandas-docs/stable/groupby.html) (not needed for this assignment, but do take a look when you get a chance)."}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"def plot_classes(df):\n    groups = pd.groupby(df, 'y')\n\n    for name, group in groups: \n        plt.plot(group.X1, group.X2, '.', label=name)\n    \n    # have equal scaling for x and y\n    plt.axis('equal') \n    # put the color legend outside the plot region\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=16) \n    plt.show()"}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"         X1        X2     y\n0  0.814772  1.413950   far\n1  0.627125  0.759336  near\n2  1.329184  0.005877   far\n3  0.656004  0.480176  near\n4  1.236489  0.318324   far\n"}],"source":"df_clean = create_data(5000, p_flip = 0)\nprint df_clean.head(5)"}
{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::b732c1f6-eb63-48be-b7bc-0d2165b5d885","text/plain":"<matplotlib.figure.Figure at 0x1122c8e10>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_clean)"}
{"cell_type":"markdown","metadata":{},"source":"Let's next create a noisy version of our dataset by assigning a nonzero \"class flip\" probability. We will use this dataset to create a predictive model below--this will be our training set."}
{"cell_type":"code","execution_count":55,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"# We will use a \"random seed\" for the (pseudo-)random dataset creation, \n# our datasets will look random, but we will get the same results each\n# time due to this reproducibility seed. To get different \n# results, simply change this random seed.\n\nTRAIN_SEED = 3\nnp.random.seed(TRAIN_SEED)\n\ndf_train = create_data(2500, p_flip=0.1)"}
{"cell_type":"code","execution_count":56,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"         X1        X2    y\n0  1.101596  0.550481  far\n1  1.416296  1.704858  far\n2  0.581809  0.879703  far\n3  1.021655  1.562559  far\n4  1.785894  0.583550  far\n"}],"source":"print df_train.head()"}
{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::bbbb23bc-cf97-4bc8-ac23-43d328cb811b","text/plain":"<matplotlib.figure.Figure at 0x1123baf50>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_train)"}
{"cell_type":"markdown","metadata":{},"source":"You can see that the two classes have mixed a bit due to the added noise."}
{"cell_type":"markdown","metadata":{"collapsed":true},"source":"### Build a decision tree classifier"}
{"cell_type":"markdown","metadata":{},"source":"We first define a function to visualize the classification trees we will create below. Don't worry too much about this, it is not central to the machine learning; it just helps create nice visual representations of the models."}
{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"from IPython.display import Image  \nfrom sklearn import tree\nimport pydot\ndef plot_tree(clf):\n    dot_data = tree.export_graphviz(clf, out_file=None, \n                             feature_names=['X1', 'X2'],\n                             class_names=['far', 'near'],  \n                             filled=True, rounded=True,  \n                             special_characters=True, impurity=False)\n    graph = pydot.graph_from_dot_data(dot_data)  \n    return Image(graph.create_png())  "}
{"cell_type":"markdown","metadata":{},"source":"Let's next try to learn from our dataset using a classification tree. For this, we will use the classification tree implementation of the popular machine learnig library `scikit-learn`. I mentioned [this tutorial](http://scikit-learn.org/stable/modules/tree.html) over email, which you can refer to as needed. \n\nThe first step is to import the `DecisionTreeClassifier` from the tree module in `scikit-learn`."}
{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier"}
{"cell_type":"markdown","metadata":{},"source":"The basic workflow in `scikit learn` is as follows:\n\n1. Create an instance of a machine learning method (e.g. a decision tree classifier), setting the parameters to desired values\n2. Use the `.fit()` method of the resulting classifier object on a dataset to learn from the data\n3. Use the `.predict()` method of the resulting classifier to make predictions on new data.\n\nThere are many helper functions that make it easier to tune models, etc., but these three steps allow you to do everything you need to do.\n\nIn our case, we will be using a classification tree with a given maximum number of leaves. Let's start by creating an instance of a `DecisionTreeClassifier` (which we will call `clf`). We are setting the max number of leaves to 3. "}
{"cell_type":"code","execution_count":16,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"clf = DecisionTreeClassifier(max_leaf_nodes=3)"}
{"cell_type":"markdown","metadata":{},"source":"Now, this `\"clf\"` is holding a decision tree classifier that can learn from any data we feed to it. It is a blank\nslate, a [tabula rasa](https://en.wikipedia.org/wiki/Tabula_rasa). Using its `fit()` method on a dataset, we will have it learn to predict. The fit method has two main inputs: the input columns of the dataset as a matrix or a data frame, and the output column. In our case, the input columns are `X1` and `X2`, so we just select them from our data frame together, and feed as the input data. The output column is the `y` column, so we feed that as the second argument."}
{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=3, min_impurity_split=1e-07,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":"clf.fit(df_train[['X1', 'X2']], df_train['y'])"}
{"cell_type":"markdown","metadata":{},"source":"Note that we don't need to set the output of this `fit()` method to anything; the \"fitting\" procedure updates our object `clf`, and saves all the tree information inside it.\n\nIn other words, our classifier, `clf`, has now learned from our data; its internal state is updated to contain the the splits/prediction rules of the resulting decision tree. If you want to dig into this object and explore its attributes, you are welcome to do so, but this is not needed."}
{"cell_type":"markdown","metadata":{},"source":"Let's next visualize our decision tree. I'm using here the helper function I defined above. "}
{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::436ccfc1-ded6-4988-bd17-32f43b99a6a5","text/plain":"<IPython.core.display.Image object>"},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":"plot_tree(clf)"}
{"cell_type":"markdown","metadata":{},"source":"As you can see, the first split (the \"root\" of the tree, shown at the top) is at `X2 <= 0.91`. If we feed a data point to our tree with `X1` greater than this value, that point ends in the \"leaf node\" on the right, and gets assigned the class prediction \"`far`\". \n\nIf `X2` is less than `0.91`, we go to the left hand node, and this one has a split at `X1 <= 0.95`. If our data point satisfies this inequality, it is sent to the left (blue) child, and gets assigned the prediction `near`. If it doesn't satisfy the inequality, it is sent to the right node, where it gets the prediction `far`. \n\nYou can see that our tree has 3 terminal, \"leaf\" nodes, and two of them have the class prediction \"far\" assigned, and one of them has the class prediction \"near\" assigned. The color coding here represents classes, and how \"sure\" the prediction is: Blue represents `near`, orange represents `far`, and darker colors represent more confident predictions.\n\nWhat is this confidence based on? It is based on the \"purity\" of the node: For the training set, how pure was each node in terms of the number of points that fell in it? Refer to the `scikit-learn` documentation on classification trees for further details on how purity is defined."}
{"cell_type":"markdown","metadata":{},"source":"Now that we have a decision tree created, we can make predictions with it. To do this, we simply use the `.predict()` method of our object, and feed in the input columns of the dataset we want to make predictions for. Let's start by predicting the classes of our training data."}
{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"y_predictions = clf.predict(df_train[['X1','X2']])"}
{"cell_type":"markdown","metadata":{},"source":"Let's create a predictions data frame to visualize our predictions: copy the original data frame, and replace the y column with predictions."}
{"cell_type":"code","execution_count":24,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"df_predictions = df_train.copy()\ndf_predictions['y'] = y_predictions"}
{"cell_type":"markdown","metadata":{},"source":"What is the fraction of correct predictions? \n\nSince NumPy treats the logicals `True` and `False` as floating point numbers `1` and `0` when you feed them into numerical functions, we can find the fraction of correct answers by simply calculating the mean of the Boolean of correct predictions."}
{"cell_type":"code","execution_count":26,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy on the training set: 0.88\n"}],"source":"print \"Accuracy on the training set:\", np.mean(df_train.y == df_predictions.y)"}
{"cell_type":"markdown","metadata":{},"source":"So we have about 88% classification accuracy on the training set, which is the set we learned from. Note that if you memorize this training set, you can get 100% accuracy! The real challenge is to learn from this training set, and make accurate predictions on a separate test set."}
{"cell_type":"markdown","metadata":{},"source":"Let's compare the correct values with the predictions visually."}
{"cell_type":"code","execution_count":27,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"The original data\n"},{"data":{"image/png":"smc-blob::bbbb23bc-cf97-4bc8-ac23-43d328cb811b","text/plain":"<matplotlib.figure.Figure at 0x114855d10>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"Our predictions\n"},{"data":{"image/png":"smc-blob::e8284fca-b285-448c-822b-a66efdd7762e","text/plain":"<matplotlib.figure.Figure at 0x11483ced0>"},"metadata":{},"output_type":"display_data"}],"source":"print \"The original data\"\nplot_classes(df_train)\nprint \"Our predictions\"\nplot_classes(df_predictions)"}
{"cell_type":"markdown","metadata":{},"source":"As you can see, our predictions represent a crude approximation to the structure of the data. This is because our tree was too shallow.\n\nLet's try a deeper tree. "}
{"cell_type":"code","execution_count":28,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=8, min_impurity_split=1e-07,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":"clf_deep = DecisionTreeClassifier(max_leaf_nodes=8)\nclf_deep.fit(df_train[['X1', 'X2']], df_train['y'])"}
{"cell_type":"markdown","metadata":{},"source":"Once again, let's visualize the resulting tree."}
{"cell_type":"code","execution_count":29,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::ff4289e0-ce1a-4024-b53b-9f39efd42bc0","text/plain":"<IPython.core.display.Image object>"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":"plot_tree(clf_deep)"}
{"cell_type":"markdown","metadata":{},"source":"This is a model with a higher degree of complexity. Once again, create predictions for the deep tree (and put them inside a data frame)."}
{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"# This 'copy' is important, you generally don't want multiple\n# variables pointing to the same data frame\ndf_predictions_deep = df_train.copy()\n\ndf_predictions_deep['y'] = clf_deep.predict(df_train[['X1','X2']])"}
{"cell_type":"code","execution_count":32,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::8fbb672c-73da-4639-8122-3654988f03b8","text/plain":"<matplotlib.figure.Figure at 0x117394550>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_predictions_deep)"}
{"cell_type":"markdown","metadata":{},"source":"This seems to be a better approximation to the data. Let's look at the accuracy."}
{"cell_type":"code","execution_count":33,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"0.89759999999999995"},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":"np.mean(df_train.y == df_predictions_deep.y)"}
{"cell_type":"markdown","metadata":{},"source":"The training set accuracy has improved. "}
{"cell_type":"markdown","metadata":{},"source":"Creating a more complex model (a deeper tree or a tree with a larger number of leaves) improved our training accuracy. What happens if we increase the complexity further?  Let's next try a much deeper tree. "}
{"cell_type":"code","execution_count":34,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=100,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":"clf_superdeep = DecisionTreeClassifier(max_leaf_nodes=100)\n\nclf_superdeep.fit(df_train[['X1', 'X2']], df_train['y'])"}
{"cell_type":"markdown","metadata":{},"source":"Evaluate predictions."}
{"cell_type":"code","execution_count":35,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"df_predictions_superdeep = df_train.copy()\n\ndf_predictions_superdeep['y'] = clf_superdeep.predict(df_train[['X1','X2']])"}
{"cell_type":"code","execution_count":36,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"0.93400000000000005"},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":"np.mean(df_train.y == df_predictions_superdeep.y)"}
{"cell_type":"code","execution_count":37,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::43150b94-1d0d-462a-b7b1-e8a6a2df6d28","text/plain":"<matplotlib.figure.Figure at 0x11738b850>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_predictions_superdeep)"}
{"cell_type":"markdown","metadata":{},"source":"We see that although the accuracy has seemingly improved, our tree started to pick up on the noise in the data; in other words, it is starting to memorize, rather than learn. "}
{"cell_type":"markdown","metadata":{},"source":"How does the tree look? "}
{"cell_type":"code","execution_count":38,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::ef979879-3aa0-4cf2-89ff-fecb82d8b525","text/plain":"<IPython.core.display.Image object>"},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":"plot_tree(clf_superdeep)"}
{"cell_type":"markdown","metadata":{},"source":"Just for fun, let's go really crazy now, and learn a tree with about a 1000 leaves."}
{"cell_type":"code","execution_count":39,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=1000,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":"clf_crazy = DecisionTreeClassifier(max_leaf_nodes=1000)\n\nclf_crazy.fit(df_train[['X1', 'X2']], df_train['y'])"}
{"cell_type":"markdown","metadata":{},"source":"And now evaluate this tree."}
{"cell_type":"code","execution_count":40,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"df_predictions_crazy = df_train.copy()\n\ndf_predictions_crazy['y'] = clf_crazy.predict(df_train[['X1','X2']])"}
{"cell_type":"code","execution_count":41,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"1.0"},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":"np.mean(df_train.y == df_predictions_crazy.y)"}
{"cell_type":"markdown","metadata":{},"source":"Our accuracy is 100% on the training set! Our model has perfectly memorized the data, including all the noise in it."}
{"cell_type":"code","execution_count":42,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::476c6ae5-58c0-4dab-8bbd-e3f31f63a0a7","text/plain":"<IPython.core.display.Image object>"},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":"plot_tree(clf_crazy)"}
{"cell_type":"markdown","metadata":{},"source":"This doesn't look like it has 1000 leaf nodes, but that's because 1000 was the max value we allowed for the number of leaves, if there aren't enough data points to warrant additional splits, the classification tree algorithm stops splitting. "}
{"cell_type":"markdown","metadata":{},"source":"Visually compare the predictions with the original classes."}
{"cell_type":"code","execution_count":52,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"The original data\n"},{"data":{"image/png":"smc-blob::bbbb23bc-cf97-4bc8-ac23-43d328cb811b","text/plain":"<matplotlib.figure.Figure at 0x12eaec6d0>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"Our predictions\n"},{"data":{"image/png":"smc-blob::bbbb23bc-cf97-4bc8-ac23-43d328cb811b","text/plain":"<matplotlib.figure.Figure at 0x1194565d0>"},"metadata":{},"output_type":"display_data"}],"source":"print \"The original data\"\nplot_classes(df_train)\nprint \"Our predictions\"\nplot_classes(df_predictions_crazy)"}
{"cell_type":"markdown","metadata":{},"source":"This is no longer \"learning\"; our superdeep tree has basically memorized our training set, with all its noise. I\n\nHow do we check this? By using a separate test set, which our model hasn't seen before."}
{"cell_type":"markdown","metadata":{},"source":"### Testing"}
{"cell_type":"markdown","metadata":{},"source":"Let's evaluate our three classifiers on the separate test set."}
{"cell_type":"code","execution_count":58,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"# Use different random seed\nTEST_SEED = 5\nassert TRAIN_SEED != TEST_SEED\n\nnp.random.seed(TEST_SEED)"}
{"cell_type":"code","execution_count":59,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"         X1        X2     y\n0  0.443986  1.299223   far\n1  1.741465  0.367162  near\n2  0.413438  0.405239  near\n3  1.837222  0.323490   far\n4  0.976822  0.939897  near\n"},{"data":{"image/png":"smc-blob::38e577e4-d414-4a97-a1d9-25f665b54744","text/plain":"<matplotlib.figure.Figure at 0x1196a2690>"},"metadata":{},"output_type":"display_data"}],"source":"# Use the same flip probability as in the training_set\ndf_test = create_data(20000, p_flip=0.1)\nprint df_test.head()\nplot_classes(df_test)"}
{"cell_type":"markdown","metadata":{},"source":"Note that we are using the same underlying sample/distribution here to create the training and the test sets. One very common problem in real-life prediction problems is a change in the distribution over time. We learn from past data, but the future distribution is somewhat different from the past. Can we still create satisfactory models? This is a difficult problem, which we will ignore."}
{"cell_type":"code","execution_count":60,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"Test scores on independent data\n-------------------------------\nShallow:    0.8685\nDeep:       0.8827\nSuperdeep:  0.86945\nCrazy:      0.81875\n"}],"source":"print \"Test scores on independent data\"\nprint \"-------------------------------\"\nprint \"Shallow:   \",\nprint np.mean(clf.predict(df_test[['X1','X2']]) == df_test.y)\n\nprint \"Deep:      \",\nprint np.mean(clf_deep.predict(df_test[['X1','X2']]) == df_test.y)\n\nprint \"Superdeep: \",\nprint np.mean(clf_superdeep.predict(df_test[['X1','X2']]) == df_test.y)\n\nprint \"Crazy:     \",\nprint np.mean(clf_crazy.predict(df_test[['X1','X2']]) == df_test.y)"}
{"cell_type":"markdown","metadata":{},"source":"We see that the second (\"deep\") tree gets the best accuracy on the test set. So you may be doing perfectly on the training set by using a crazy deep tree, but your **generalization** capability to new data will be really low; you will have **overfit** to the training set. On the other extreme, with a shallow tree, you will **underfit**, and not learn all the relevant structure in the data.\n\nHow do we find the \"sweet spot\" between overfitting and underfitting? By keeping a portion of our training data aside, and **tuning** the depth of our tree by monitoring the performance on that **holdout set**."}
{"cell_type":"markdown","metadata":{},"source":"### Tuning a decision tree"}
{"cell_type":"markdown","metadata":{},"source":"`scikit-learn` has helpful functions for parameter tuning which you are welcome to learn about, but it will be more informative for us to do this manually ourselves in this assignment."}
{"cell_type":"markdown","metadata":{},"source":"Once again, we will pretend that we only have access to our training set to create (or tune) our models. We will start by putting aside a part of the training as a **holdout set**."}
{"cell_type":"code","execution_count":61,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"# Let's fix the number of points we will put aside as the holdout set\n# to 20% of the training set (why 20%? no good reason)\n\nn_train_full = len(df_train)\nn_train_holdout = n_train_full / 5"}
{"cell_type":"markdown","metadata":{},"source":"We will do the sampling by using the integer indices of the data frame using the `.iloc[]` method to access the data.\n\nMy aim in doing this sampling explicitly is to get you familiarized with the nitty-gritty of train/holdout splits. We could also use Pandas to do the sampling for us, which is much easier, but not as informative."}
{"cell_type":"code","execution_count":68,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"train_full_inds = range(n_train_full)\n\n# A random seed for reproducibility; change this number to get a different sample\nHOLDOUT_SEED = 10\nnp.random.seed(HOLDOUT_SEED)"}
{"cell_type":"markdown","metadata":{},"source":"Now split the set of available training row indices into two pieces, a \"`train_train`\" piece to build trees on, and a \"`train_holdout`\" piece to evaluate the trees."}
{"cell_type":"code","execution_count":69,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"train_holdout_inds = np.random.choice(train_full_inds, size = n_train_holdout, replace=False)\ntrain_train_inds   = np.setdiff1d(train_full_inds, train_holdout_inds)"}
{"cell_type":"code","execution_count":71,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"train_holdout_inds.sort()"}
{"cell_type":"code","execution_count":72,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"[ 1  5 11 16 17 18 20 25 27 28]\n[ 0  2  3  4  6  7  8  9 10 12]\n"}],"source":"# Look at a few examples of our chosen indices; the two sets should be disjoint\nprint train_holdout_inds[:10]\nprint train_train_inds[:10]"}
{"cell_type":"markdown","metadata":{},"source":"Now using these indices and the `.iloc[]` method of Pandas, split the training set into two pieces."}
{"cell_type":"code","execution_count":73,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"df_train_train = df_train.iloc[train_train_inds]\ndf_train_holdout = df_train.iloc[train_holdout_inds]"}
{"cell_type":"markdown","metadata":{},"source":"Take a quick look at the split data."}
{"cell_type":"code","execution_count":74,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/html":"smc-blob::0531af6a-b0cd-412e-b69f-0987b5f6eeaa","text/plain":"         X1        X2     y\n0  1.101596  0.550481   far\n2  0.581809  0.879703   far\n3  1.021655  1.562559   far\n4  1.785894  0.583550   far\n6  0.251171  0.528810  near"},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":"df_train_train.head()"}
{"cell_type":"code","execution_count":75,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/html":"smc-blob::b19a8dd5-d0ab-4c1e-bece-626e52c53f40","text/plain":"          X1        X2     y\n1   1.416296  1.704858   far\n5   1.792586  1.403474   far\n11  0.913666  0.198605   far\n16  0.047964  0.494611  near\n17  1.117708  1.024084   far"},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":"df_train_holdout.head()"}
{"cell_type":"code","execution_count":76,"metadata":{"collapsed":false,"scrolled":true,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::da31931b-8616-435e-a1a8-bb67ae9bc538","text/plain":"<matplotlib.figure.Figure at 0x1196a2290>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_train_train)"}
{"cell_type":"code","execution_count":77,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::47bd2e15-b1df-4103-bd07-032f7f62bcef","text/plain":"<matplotlib.figure.Figure at 0x12e9e8d50>"},"metadata":{},"output_type":"display_data"}],"source":"plot_classes(df_train_holdout)"}
{"cell_type":"markdown","metadata":{},"source":"The simpler, Pandas way of doing this split would be to use the `sample` method of Pandas DataFrame objects:\n```\ndf_train_holdout = df_train.sample(frac = 0.2)\ndf_train_train   = df_train.drop(df_train_holdout.index)\n```\nWe won't be doing this for now."}
{"cell_type":"markdown","metadata":{},"source":"Now that we have a training piece (`train_train`) and a holdout piece (`train_holdout`), let's try a whole bunch of trees, and see which size (`max_leaf_nodes`) is the best. We will build a tree on the training set, and evaluate it on the holdout set."}
{"cell_type":"code","execution_count":79,"metadata":{"collapsed":false,"scrolled":true,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"max_leaf_nodes = 002 Training accuracy: 0.74, Holdout accuracy: 0.72\nmax_leaf_nodes = 004 Training accuracy: 0.88, Holdout accuracy: 0.88\nmax_leaf_nodes = 006 Training accuracy: 0.90, Holdout accuracy: 0.89\nmax_leaf_nodes = 008 Training accuracy: 0.90, Holdout accuracy: 0.89\nmax_leaf_nodes = 010 Training accuracy: 0.90, Holdout accuracy: 0.90\nmax_leaf_nodes = 012 Training accuracy: 0.91, Holdout accuracy: 0.90\nmax_leaf_nodes = 014 Training accuracy: 0.91, Holdout accuracy: 0.90\nmax_leaf_nodes = 016 Training accuracy: 0.91, Holdout accuracy: 0.90\nmax_leaf_nodes = 018 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 020 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 022 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 024 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 026 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 028 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 030 Training accuracy: 0.91, Holdout accuracy: 0.89\nmax_leaf_nodes = 032 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 034 Training accuracy: 0.92, Holdout accuracy: 0.90\nmax_leaf_nodes = 036 Training accuracy: 0.92, Holdout accuracy: 0.90\nmax_leaf_nodes = 038 Training accuracy: 0.92, Holdout accuracy: 0.90\nmax_leaf_nodes = 040 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 042 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 044 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 046 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 048 Training accuracy: 0.92, Holdout accuracy: 0.89\nmax_leaf_nodes = 050 Training accuracy: 0.92, Holdout accuracy: 0.88\nmax_leaf_nodes = 052 Training accuracy: 0.92, Holdout accuracy: 0.88\nmax_leaf_nodes = 054 Training accuracy: 0.92, Holdout accuracy: 0.88\nmax_leaf_nodes = 056 Training accuracy: 0.93, Holdout accuracy: 0.88\nmax_leaf_nodes = 058 Training accuracy: 0.93, Holdout accuracy: 0.88\nmax_leaf_nodes = 060 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 062 Training accuracy: 0.93, Holdout accuracy: 0.88\nmax_leaf_nodes = 064 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 066 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 068 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 070 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 072 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 074 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 076 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 078 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 080 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 082 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 084 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 086 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 088 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 090 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 092 Training accuracy: 0.93, Holdout accuracy: 0.87\nmax_leaf_nodes = 094 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 096 Training accuracy: 0.94, Holdout accuracy: 0.86\nmax_leaf_nodes = 098 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 100 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 102 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 104 Training accuracy: 0.94, Holdout accuracy: 0.86\nmax_leaf_nodes = 106 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 108 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 110 Training accuracy: 0.94, Holdout accuracy: 0.86\nmax_leaf_nodes = 112 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 114 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 116 Training accuracy: 0.94, Holdout accuracy: 0.87\nmax_leaf_nodes = 118 Training accuracy: 0.94, Holdout accuracy: 0.86\n"}],"source":"# Dictionaries to hold the accuracy values we encounter\ntrain_accuracies = {}\nholdout_accuracies = {}\n\n# The range of max_leaf_nodes to try\nmax_leaf_nodes_values = range(2,120,2)\n\n# Loop over all values\nfor my_max_leaf_nodes in max_leaf_nodes_values:\n\n    # Create a classifier with this given number of max_leaf_nodes\n    clf = DecisionTreeClassifier(max_leaf_nodes=my_max_leaf_nodes)\n    # Fit the created classifier to the train_train data\n    clf.fit(df_train_train[['X1','X2']], df_train_train.y)\n\n    # Make predictions on the training set\n    train_preds = clf.predict(df_train_train[['X1','X2']])\n\n    # Make predictions on the holdout set\n    holdout_preds = clf.predict(df_train_holdout[['X1','X2']])\n\n    # Evaluate accuracy on each data set\n    train_accuracy = np.mean(train_preds==df_train_train.y)\n    holdout_accuracy = np.mean(holdout_preds == df_train_holdout.y)\n\n    print \"max_leaf_nodes = {:03} Training accuracy: {:03.2f}, Holdout accuracy: {:03.2f}\".\\\n        format(my_max_leaf_nodes,train_accuracy, holdout_accuracy)\n\n    # Record the accuracies\n    train_accuracies[my_max_leaf_nodes] = train_accuracy\n    holdout_accuracies[my_max_leaf_nodes] = holdout_accuracy"}
{"cell_type":"code","execution_count":80,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"# Compile the training and holdout accuracies into a data frame called tuning_accuracies\ntuning_accuracies_df = pd.DataFrame({'train':train_accuracies, 'holdout': holdout_accuracies})\ntuning_accuracies_df.index.name = 'max_leaf_nodes'"}
{"cell_type":"markdown","metadata":{},"source":"Take a quick look at the compiled accuracies."}
{"cell_type":"code","execution_count":81,"metadata":{"collapsed":false,"scrolled":true,"trusted":false},"outputs":[{"data":{"text/html":"smc-blob::082efa53-25f3-4e0c-8485-2ae6e3706de8","text/plain":"                holdout   train\nmax_leaf_nodes                 \n2                 0.720  0.7420\n4                 0.884  0.8790\n6                 0.890  0.8970\n8                 0.892  0.9015\n10                0.896  0.9040"},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":"tuning_accuracies_df.head()"}
{"cell_type":"markdown","metadata":{},"source":"Let's next visualize the accuracies we encountered."}
{"cell_type":"code","execution_count":89,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::774070c0-dfca-49de-96aa-712fa892743c","text/plain":"<matplotlib.figure.Figure at 0x12c863d50>"},"metadata":{},"output_type":"display_data"}],"source":"plt.figure(figsize=(8,6))\nplt.title(\"Accuracy as a function of max_leaf_nodes (a measure of max tree depth)\", fontsize=16, y=1.02)\nplt.plot(tuning_accuracies_df.train, 'o-', label='training set accuracy')\nplt.plot(tuning_accuracies_df.holdout, 'o-', label='holdout set accuracy')\nplt.xlabel('max_leaf_nodes', fontsize=14)\nplt.ylabel('Accuracy', fontsize=14)\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=16)\nplt.show()"}
{"cell_type":"markdown","metadata":{},"source":"We see that while the training set accuracy keeps increasing as we increase `max_leaf_nodes`, the holout set accuracy hits a peak and starts to go down. As we increase `max_leaf_nodes`, our tree starts to memorize, or overfit to the training set, and starts to lose the generalization capability; it does worse on data points it hasn't seen before. Using a holdout set allowed ourselves to have an independent evaluation of each tree, and to avoid fooling ourselves into thinking that we were getting better and better with higher `max_leaf_nodes`."}
{"cell_type":"markdown","metadata":{},"source":"Finally, let's evaluate our best model configuration on a separate test set."}
{"cell_type":"code","execution_count":92,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"The best value found for max_leaf_nodes:  10\n"}],"source":"best_max_leaf_nodes = tuning_accuracies_df.holdout.argmax()\nprint \"The best value found for max_leaf_nodes: \", best_max_leaf_nodes"}
{"cell_type":"markdown","metadata":{},"source":"Create a final model on the full training set, using this best value."}
{"cell_type":"code","execution_count":93,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=118,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":"clf_best = DecisionTreeClassifier(max_leaf_nodes=best_max_leaf_nodes)\nclf.fit(df_train[['X1','X2']], df_train['y'])"}
{"cell_type":"markdown","metadata":{},"source":"Create new test set."}
{"cell_type":"code","execution_count":95,"metadata":{"collapsed":false,"trusted":false},"outputs":[],"source":"# Use different random seed\nNEW_TEST_SEED = 15\nnp.random.seed(NEW_TEST_SEED)\n\n# Use the same flip probability as in the training_set\ndf_test_final = create_data(20000, p_flip=0.1)"}
{"cell_type":"code","execution_count":99,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"Final accuracy of the best model on the test set:  0.86915\nThe best holdout accuracy was:  0.896\n"}],"source":"final_test_accuracy = np.mean(clf.predict(df_test_final[['X1','X2']]) == df_test_final['y'])\nprint \"Final accuracy of the best model on the test set: \", final_test_accuracy\nprint \"The best holdout accuracy was: \", tuning_accuracies_df.holdout.max()"}
{"cell_type":"markdown","metadata":{},"source":"You can see that the holdout accuracy is better than the final test accuracy; so if we hadn't done this final test (for which we used a much larger test set than the holdout set), we would over estimate the performance of our model. \n\nThe accuracy on the holdout set depends on the particular sample used as a holdout, and will vary from sample to sample. There are ways to reduce this variance; one such way is called cross-validation (mentioned in class). We will use this below in the Titanic example below."}
{"cell_type":"markdown","metadata":{},"source":"# Titanic: The assignment"}
{"cell_type":"markdown","metadata":{},"source":"### Read, pre-process data"}
{"cell_type":"markdown","metadata":{},"source":"- Upload the Titanic datasets you got from Kaggle, `train.csv` and `test.csv`, to the directory of this assigment."}
{"cell_type":"markdown","metadata":{},"source":"- Using Pandas,\n  - Read the training dataset `train.csv` into the variable `titanic`.\n  - Read the testing dataset `test.csv` into the variable titanic_test."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"## your code here\ntitanic = \ntitanic_test = "}
{"cell_type":"markdown","metadata":{},"source":"- Using Pandas, drop the following columns from both `titanic` and `titanic_test:\n  - `Name`, `Cabin`, `Ticket`, `PassengerId`\n- Look at a few rows of `titanic` and `titanic_test` to make sure that you successfully dropped these columns."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Create two lists, `cat_cols` and `num_cols` that contain the list of categorical and numerical columns in the data frame `titanic`, respectively. (You can refer to the previous homeworks, or use the `dtype` attribute of columns)\n- Print the `cat_cols` and `num_cols` variables to do a manual sanity check."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"## your code here\ncat_cols = \nnum_cols = "}
{"cell_type":"markdown","metadata":{},"source":"### Exploratory data analysis"}
{"cell_type":"markdown","metadata":{},"source":"- Create histograms for all the numerical columns in `titanic`."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Print the value counts of all the catogries in all categorical columns\n- Hint: There should be two categorical columns"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Create bar plots of the value counts for all categorical columns\n- You should have two such bar plots, one for each categorical column"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Print the number of missing values in each one of the columns of `titanic`\n- You should find that one numerical column and one categorical column have missing values."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Create a dictionary called `medians` whose keys are the names of the numerical columns, and whose values are the medians of the corresponding columns"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Using the medians dictionary, replace all the missing **numerical** values in `titanic` by the median of the corresponding column.\n- Do this by creating a new data frame called `titanic_filled`--do not update `titanic` itself."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Next, create a dictionary called `most_freq_cats` whose keys are the names of the categorical columns and whose values are the most frequent category of the corresponding columns"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Using the medians dictionary, replace all the missing **categorical** values in `titanic_filled` by the most frequent category of the corresponding column.\n- This time, do this by updating `titanic_filled`. "}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- After this step, this data frame should not have any missing values (we replaced both the numerical and the categorical missing values); check that there are no more missing values in `titanic_filled`"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Look at the first few rows of `titanic_filled`"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"We will next convert the categorical columns to numerical ones. For this purpose, we will use the `.get_dummies()` method of Pandas. Read about it [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) if you haven't already. "}
{"cell_type":"markdown","metadata":{},"source":"- Using the `.get_dummies()` method of Pandas, create a variable names `titanic_all_num`, that contains an all-numerical version of `titanic_filled."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Look at the first few rows of `titanic_all_num`\n- How many columns does `titanic_all_num` have? How manu columns did `titanic_filled` have?"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"### Train-holdout split"}
{"cell_type":"markdown","metadata":{},"source":"- Using either the `.sample()` method of Pandas DataFrame objects or manually sampling the indices using `NumPy`, split the data frame `titanic_all_num` into two picece: `titanic_holdout` and `titanic_train`. I leave the fractional sizes of the two pieces to you.\n- Make sure to use a random seed so that your samples are reproducible (note that in Pandas this is done by a parameter to the `.sample()` function)."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"### Creating one model"}
{"cell_type":"markdown","metadata":{},"source":"- Using the `DecisionTreeClassifier` of `scikit-learn`, build a single tree model using the training data. Feel free to pick a parameter setting of your choice, or go with the default settings of `DecisionTreeClassifier`."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Using your trained model, make two sets of predictions, one for the training set, the other for the holdout set."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Obtain the classification accuracy (i.e., the fraction of correct predictions) of the two sets of predictions"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"### Tuning a classification tree"}
{"cell_type":"markdown","metadata":{},"source":"- Loop over a range of values for `max_leaf_nodes`\n  - For each value, build a classification tree model with that value for the `max_leaf_nodes` parameter\n  - Using the model, make predictions on the training set and the holdout set\n  - Evaluate the classification accuracy (fraction of correct predictions) on the training and holdout sets\n  - Compile the two sets of predictions into a data frame"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Plot the training and holdout accuracies as a function of the `max_leaf_nodes` value"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Obtain the value of `max_leaf_nodes` with the best accuracy on the holdout set"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Using the best value of `max_leaf_nodes` found, train a new classification tree, this time using the full dataset (training + holdout)"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Using this final model, make predictions on the test set. Note that you will have to transform the test set in the same way that you transformed the training set. "}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"### Bonus: 5-fold cross-validation"}
{"cell_type":"markdown","metadata":{},"source":"In the accuracy plots for the holdout set, you may have observed that the dependence of accuracy on `max_leaf_nodes` seems a little irregular. This is because of the small size of your (holdout) dataset. Due to this irregularity, it is hard to be confident about the best value for the `max_leaf_nodes` found. One way to deal with this irregularity is to use cross-validation. As mentioned in class, this means splitting your training set into a number of (say 5) equal-sized pieces, and for each parameter value (of `max_leaf_nodes`) letting each piece be a holdout set once. To evaluate each value of `max_leaf_nodes`, you calculate the average of the 5 accuracy values obtained. In this section, we will use 5-fold cross-validation to tune a model."}
{"cell_type":"markdown","metadata":{},"source":"#### Create the cross-validation (CV) \"folds\""}
{"cell_type":"markdown","metadata":{},"source":"- Go back to `titanic_all_num`, and create a variable `num_inds`, equal to the the number of its rows (or indices).\n- Create another variable, `all_inds`, that holds a NumPy array of integers, starting from 0, going all the way up to `num_inds` (not inclusive). This is the set of all integer indices for our training set."}
{"cell_type":"markdown","metadata":{},"source":"Below, I will give examples for the case where there are only 20 rows, i.e., num_inds = 20, to help clarify what I mean."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"If num_inds = 20, then all_inds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]."}
{"cell_type":"markdown","metadata":{},"source":"- Using the NumPy function `np.random.shuffle()`, shuffle the array `all_inds` in place."}
{"cell_type":"markdown","metadata":{},"source":"If num_inds = 20, this may, for example, make all_inds = [19,  3, 18,  6, 13,  4,  0, 17, 12, 11, 15, 10,  9,  2, 16,  7,  8,\n        1,  5, 14]"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"We will next split this set of shuffled indices into 5 approximately equal-sized subsets. In order to do this, we start by creating the split points. "}
{"cell_type":"markdown","metadata":{},"source":"- Create a variable named `index_bds` that contains a 6-element, approximately equally-spaced array of integers starting at 0, ending at `num_inds` (inclusive). \n\n- For example\n  - If num_inds were 20, our array would be completely evenly spaced\n    - [0, 4, 8, 12, 16, 20]\n  - If num_inds were 22, our array can't be evenly spaced, but it could be something like\n    - [0, 4, 8, 13, 17, 22]\n- Make sure that your array consists of integers, not floats."}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Create a dictionary called `cv_holdout_inds`, whose keys are integers from 0 to 4 (inclusive), and its values are the elements of `all_inds` at the positions between the corresponding index_bds.\n- For example\n  - In our example above, the shuffled `all_inds` was `[19,  3, 18,  6, 13,  4,  0, 17, 12, 11, 15, 10,  9,  2, 16,  7,  8, 1,  5, 14]`\n  - This will make, \n```\n     cv_holdout_inds = {0: [19,  3, 18,  6],\n                        1: [13,  4,  0, 17],\n                        2: [12, 11, 15, 10],\n                        3: [9,  2, 16,  7],\n                        4: [8, 1,  5, 14]}\n```"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"- Create a second dictionary, called `cv_train_inds`, whose keys are the same as those of `cv_holdout_inds`, but whose values are complement of the indices in the corresponding `cv_holdout_inds`\n- Continuing the example above, this would make:\n```\ncv_train_inds = {0: array([13,  4,  0, 17, 12, 11, 15, 10,  9,  2, 16,  7,  8,  1,  5, 14]),\n                  1: array([19,  3, 18,  6, 12, 11, 15, 10,  9,  2, 16,  7,  8,  1,  5, 14]),\n                  2: array([19,  3, 18,  6, 13,  4,  0, 17,  9,  2, 16,  7,  8,  1,  5, 14]),\n                  3: array([19,  3, 18,  6, 13,  4,  0, 17, 12, 11, 15, 10,  8,  1,  5, 14]),\n                  4: array([19,  3, 18,  6, 13,  4,  0, 17, 12, 11, 15, 10,  9,  2, 16,  7])}\n```"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}
{"cell_type":"markdown","metadata":{},"source":"#### Using the folds, tune a model"}
{"cell_type":"markdown","metadata":{},"source":"- Now, once again, write a loop that goes over a range of values for `max_leaf_nodes`, but this time, for each value, it builds 5 models instead of a single model; one model for each cv_train_inds value\n- You will do this by subsetting titanic_all_num using the 5 different lists in `cv_train_inds`, and building a separate model for each list. Note that you can do this by looping over the 5 folds.\n- For each model you build, evaluate the accuracy on the **corresponding** holdout set.\n- Then average the 5 holdout accuracies, and store that value for as the 5-fold cross-validation accuracy for the `max_leaf_nodes` value tried\n- Finally, as in the holdout tuning, plot the cross-validation accuracy as a function of the `max_leaf_nodes` values tried, and pick the best `max_leaf_nodes` value\n- Train a model on the full dataset `titanic_all_num` using the best value found\n- Finally, make predictions on the test set, using this best value found"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":""}